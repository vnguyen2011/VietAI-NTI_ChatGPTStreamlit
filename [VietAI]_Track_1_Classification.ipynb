{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vnguyen2011/VietAI-NTI_ChatGPTStreamlit/blob/main/%5BVietAI%5D_Track_1_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Project - Sử dụng OpenAI trong thực tế & Fine-tune mô hình\n",
        "Bài tập này tổng bao gồm 200 điểm, với 2 sections:\n",
        "- Section 1 bao gồm TODO 1, TODO 2: 100 tổng điểm\n",
        "- Section 2 bao gồm TODO 3, TODO 4: 100 điểm tổng\n",
        "\n",
        "This exercise has 200 points total, consists of 2 sections:\n",
        "- Section 1 includes TODO 1, TODO 2: Total of 100 points.\n",
        "- Section 2 encompasses TODO 3, TODO 4: Total of 100 points."
      ],
      "metadata": {
        "id": "wucQHISSnCP5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Cài đặt và import các thư viện cần thiết"
      ],
      "metadata": {
        "id": "NabxsUmOoAk7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZOaRKmzcW9n",
        "outputId": "7d7d2787-35ba-4ad4-84f6-5b06b47b9aa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.14.6-py3-none-any.whl (493 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.7/493.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Collecting huggingface-hub<1.0.0,>=0.14.0 (from datasets)\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (3.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: dill, multiprocess, huggingface-hub, openai, datasets\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.14.6 dill-0.3.7 huggingface-hub-0.18.0 multiprocess-0.70.15 openai-0.28.1\n"
          ]
        }
      ],
      "source": [
        "!pip install openai datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from datasets import load_dataset\n",
        "import os"
      ],
      "metadata": {
        "id": "9d5CH5BQchos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Cấu hình OpenAI API Key\n",
        "Sau khi đăng ký API key, các bạn chép key giống định dạng sau `sk-L7qQ...DN98XT` vào các chuỗi đang để trống bên dưới."
      ],
      "metadata": {
        "id": "Tqb1mQ1huybk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = \"\" ## To configure OpenAI API\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\" ## To configure langchain connections with OpenAI"
      ],
      "metadata": {
        "id": "kTUFHndpcz9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Triển khai"
      ],
      "metadata": {
        "id": "YOGS69gFCeoh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[ENGLISH BELOW]**\n",
        "\n",
        "**SECTION 1 (100 điểm): [TODO 1]**\n",
        "\n",
        "**TODO 1: (40 điểm) Chuẩn bị Dataset**\n",
        "\n",
        "- Nhiệm vụ của bạn là tự tìm dataset phù hợp cho bài toán\n",
        " - (20 điểm) Tìm một dataset dùng để phân loại dữ liệu (classification), khuyến khích liên quan đến lĩnh vực làm việc cá nhân.\n",
        " - (20 điểm) Dataset của bạn nên có 5+ nhãn (labels) phân loại.\n",
        "- (0 điểm) Nếu bạn không tìm được dataset phù hợp hoặc muốn sử dụng dataset mẫu được cung cấp bởi VietAI:\n",
        " - **Emoji classification**: Phân loại tweets vào emoji phù hợp nhất để miêu tả tweet đó: https://huggingface.co/datasets/tweet_eval/viewer/emoji/train\n",
        "------------\n",
        "**[VIETNAMESE ABOVE]**\n",
        "\n",
        "**SECTION 1 (100 points): [TODO 1]**\n",
        "\n",
        "**TODO 1: (40 points) Prepare dataset**\n",
        "\n",
        "- Your task is to find the appropriate dataset for the problem\n",
        "  - (20 points) Find a dataset used for data classification (classification), preferably related to personal work field.\n",
        "  - (20 points) Your Dataset should have 5+ classification labels.\n",
        "- (0 points) If you cannot find a suitable dataset or want to use the sample dataset provided by VietAI:\n",
        "  - **Emoji classification**: Classify tweets into the most suitable emoji to describe that tweet: https://huggingface.co/datasets/tweet_eval/viewer/emoji/train\n"
      ],
      "metadata": {
        "id": "JoL8-F1YvdQ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dưới đây là đoạn code hướng dẫn bạn chuẩn bị dữ liệu được VietAI cung cấp. Chúng ta sẽ sử dụng hàm `load_dataset` của thư viện `datasets` của Hugging Face"
      ],
      "metadata": {
        "id": "MkWaukfKxzkT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"tweet_eval\"\n",
        "\n",
        "train_dataset = dataset = load_dataset(data_path, \"emoji\", split = \"train\") ## Train data\n",
        "valid_dataset = load_dataset(data_path, \"emoji\", split = \"validation\") ## Valid data\n",
        "test_dataset = load_dataset(data_path, \"emoji\", split = \"test\") ## Test Data"
      ],
      "metadata": {
        "id": "bQ9GeMChe9TD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[ENGLISH BELOW]**\n",
        "\n",
        "Trong học máy, một tập dữ liệu thường được chia thành ba phần: tập huấn luyện, tập kiểm định, và tập kiểm tra. Dưới đây là mục đích của từng phần:\n",
        "\n",
        "1. **Tập Huấn Luyện (Train Set)**: Đây là phần lớn nhất của dữ liệu, được sử dụng để \"dạy\" mô hình máy học. Đó giống như sách giáo khoa dành cho một học sinh; nó chứa các ví dụ mà mô hình học hỏi từ đó.\n",
        "\n",
        "2. **Tập Kiểm Định (Validation Set)**: Phần này được sử dụng để điều chỉnh các tham số của mô hình và để ngăn chặn tình trạng quá khớp. Quá khớp là khi mô hình hoạt động tốt trên dữ liệu huấn luyện nhưng kém trên dữ liệu mới, chưa từng thấy. Tập kiểm định giống như một bài kiểm tra giả định để học sinh luyện tập trước khi thi cuối kỳ. Nó giúp kiểm tra hiệu suất trong quá trình huấn luyện.\n",
        "\n",
        "3. **Tập Kiểm Tra (Test Set)**: Đây là phần dữ liệu riêng biệt không được mô hình thấy trong quá trình huấn luyện hoặc kiểm định. Nó được sử dụng để đánh giá hiệu suất của mô hình sau khi quá trình huấn luyện hoàn tất. Tập kiểm tra giống như bài thi cuối cùng cho học sinh, đánh giá xem mô hình đã học tốt đến mức nào.\n",
        "\n",
        "Lý do chúng ta cần phải chia những phần này là để đảm bảo rằng mô hình của chúng ta có khả năng tổng quát hóa tốt đối với dữ liệu mới, chưa từng thấy, không chỉ là dữ liệu nó được huấn luyện trên. Điều này giúp xây dựng những mô hình mạnh mẽ có khả năng đưa ra dự đoán chính xác trong các tình huống thực tế, ngoài môi trường huấn luyện.\n",
        "\n",
        "----------------------\n",
        "**[VIETNAMESE ABOVE]**\n",
        "\n",
        "In machine learning, a dataset is typically split into three parts: training, validation, and test sets. Here's what each of them is for:\n",
        "\n",
        "1. **Training Set**: This is the largest portion of the data, which is used to train the machine learning model. It's like the textbook for a student; it contains examples that the model learns from.\n",
        "\n",
        "2. **Validation Set**: This set is used to tune the model's parameters and to prevent overfitting. Overfitting is when the model performs well on the training data but poorly on new, unseen data. The validation set acts like a mock exam for the student to practice on before the final exam. It helps in checking the performance during the training process.\n",
        "\n",
        "3. **Test Set**: This is a separate portion of data that is not seen by the model during the training or validation phases. It is used to evaluate the model's performance after the training is complete. The test set is like the final exam for the student, assessing how well the model has learned overall.\n",
        "\n",
        "The reason we need these splits is to make sure that our model can generalize well to new, unseen data, not just the data it was trained on. This helps in building robust models that make accurate predictions in real-world situations, outside of the training environment."
      ],
      "metadata": {
        "id": "Wlpdxg62lY7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNxlMKW_fe1a",
        "outputId": "0575a75b-decb-4102-8a75-113d5bf479b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label'],\n",
              "    num_rows: 45000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Length of dataset:\", len(dataset))\n",
        "print(\"Example data: Index 1:\", dataset[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJbUyHW0fk1j",
        "outputId": "8641b9a6-3301-42ab-9ec9-ce94d8bd31d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of dataset: 45000\n",
            "Example data: Index 1: {'text': \"Time for some BBQ and whiskey libations. Chomp, belch, chomp! (@ Lucille's Smokehouse Bar-B-Que)\", 'label': 19}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Đây là nhãn dữ liệu mà chúng ta sẽ dự đoán"
      ],
      "metadata": {
        "id": "TWKwThXVkJ1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset[0][\"label\"]) ## Nhãn của data 0\n",
        "print(dataset[1][\"label\"]) ## Nhãn của data 1\n",
        "print(any(type(x) == int for x in dataset[\"label\"])) ## Kiểm tra xem nhãn có phải là int hay không"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1FsfJgG3TK7",
        "outputId": "cf6b3520-57ed-40ee-98c5-74d4645428bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n",
            "19\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do các `label` đều ở dạng **int**, không có quá nhiều ý nghĩa với mô hình, nên ta có thể thêm chú thích rõ ràng cho mỗi `label`:"
      ],
      "metadata": {
        "id": "ipnXE1UI3k6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = {\n",
        "    0: \"black heart\",\n",
        "    1: \"smiling face with heart-eyes\",\n",
        "    2: \"face with tears of joy\",\n",
        "    3: \"two heart\",\n",
        "    4: \"fire\",\n",
        "    5: \"smiling face with smiling eyes\",\n",
        "    6: \"smiling face with sunglasses\",\n",
        "    7: \"sparkles\",\n",
        "    8: \"blue heart\",\n",
        "    9: \"face blowing a kiss\",\n",
        "    10: \"camera\",\n",
        "    11: \"United States\",\n",
        "    12: \"sun\",\n",
        "    13: \"purple heart\",\n",
        "    14: \"winking face\",\n",
        "    15: \"hundred point symbol\",\n",
        "    16: \"beaming face with smilig eyes\",\n",
        "    17: \"Christmas tree\",\n",
        "    18: \"camera with flash\",\n",
        "    19: \"winking face with tongue\",\n",
        "    }"
      ],
      "metadata": {
        "id": "KW2ps1_afoc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[ENGLISH BELOW]**\n",
        "\n",
        "**SECTION 1 (100 điểm): [TODO 2]**\n",
        "\n",
        "**TODO 2: (60 điểm) Giải quyết bài toán trên dữ liệu đã chuẩn bị bằng prompting**\n",
        "\n",
        "- Mục tiêu: Dự đoán chính xác nhãn dán cho dataset\n",
        " - (30 điểm) Áp dụng kỹ thuật Zero-shot trên dataset\n",
        " - (30 điểm) Áp dụng các kỹ thuật prompting trên dataset (Few-shot, Chain of Thought (CoT))\n",
        "------------\n",
        "**[VIETNAMESE ABOVE]**\n",
        "\n",
        "**SECTION 1 (100 points): [TODO 2]**\n",
        "\n",
        "**TODO 2: (60 points) Solve problems on prepared data using prompting**\n",
        "\n",
        "- Goal: Correctly predict labels for the dataset\n",
        "  - (30 points) Apply Zero-shot technique on dataset\n",
        "  - (30 points) Apply prompting techniques on dataset (Few-shot, Chain of Thought (CoT))\n"
      ],
      "metadata": {
        "id": "N6YMgr-L5z5_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Gợi ý:***\n",
        "\n",
        "Mục tiêu của chúng ta là dự đoán chính xác nhãn cho dataset, vậy nên ta cần phải tạo mẫu prompt phù hợp với yêu cầu. Prompt **có thể** có cấu trúc như sau:\n",
        "##`prompt = <task desciption> + <instruction> + <examples> + <label>`\n",
        "Trong đó:\n",
        "\n",
        "`task description`: mô tả nhiệm vụ\n",
        "\n",
        "`instruction`: yêu cầu thực hiện nhiệm vụ\n",
        "\n",
        "`examples`: ví dụ (thường sử dụng trong one-shot, few-shot)\n",
        "\n",
        "`label`: danh sách các nhãn (ví dụ: `labels` trong TODO 1)\n"
      ],
      "metadata": {
        "id": "2zrSsSmU7i5d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[ENGLISH BELOW]**\n",
        "\n",
        "**SECTION 2 (100 điểm): [TODO 3]**\n",
        "\n",
        "**TODO 3: (60 điểm) Giải quyết bài toán bằng fine-tuning**\n",
        "\n",
        "- Mục tiêu: Dự đoán chính xác nhãn dán cho dataset\n",
        " - (40 điểm) Áp dụng kĩ thuật fine-tuning đã được học vào dataset\n",
        " - (20 điểm tối đa) Bonus point:\n",
        "   - (10 điểm) Phân tích và so sánh performance giữa các kĩ thuật khác nhau\n",
        "   - (10 điểm) Thay đổi số lượng dữ liệu để fine-tune và quan sát mối quan hệ giữa lượng dữ liệu và model performance\n",
        "------------\n",
        "**[VIETNAMESE ABOVE]**\n",
        "\n",
        "**SECTION 2 (100 points): [TODO 3]**\n",
        "\n",
        "**TODO 3: (60 points) Solve the problem with fine-tuning**\n",
        "\n",
        "- Goal: Correctly predict labels for dataset\n",
        "  - (40 points) Apply the learned fine-tuning technique to the dataset\n",
        "  - (20 points maximum) Bonus point:\n",
        "    - (10 points) Analyze and compare performance between different techniques\n",
        "    - (10 points) Change the amount of data to fine-tune and observe the relationship between the amount of data and model performance\n"
      ],
      "metadata": {
        "id": "oQP576ADpSFc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Gợi ý:***\n",
        "\n",
        "- Khi sử dụng dữ liệu được cung cấp của VietAI, để lấy một subset trong dữ liệu gốc, ta có thể làm như sau:\n"
      ],
      "metadata": {
        "id": "TFtHIBEYuu_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = 1000\n",
        "samples_dataset = dataset.select(range(num_samples))\n",
        "\n",
        "# or\n",
        "samples_dataset = dataset.shuffle(seed = 42).select(range(num_samples))\n",
        "samples_dataset"
      ],
      "metadata": {
        "id": "-ZxojQVuv0id",
        "outputId": "05504378-d69b-46be-f612-f075b6dc5635",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label'],\n",
              "    num_rows: 1000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Đối với bài toán classification, ta có thể đánh giá performance qua các metrics như Accuracy, Precision, Recall hoặc F1-score\n",
        "\n",
        "- Input:\n",
        " - `y_true`: Đây là labels thực tế - true labels.\n",
        " - `y_pred`: Đây là labels được dự đoán bởi mô hình - predicted labels.\n",
        "\n",
        " Mục tiêu của chúng ta là làm sao `y_pred` gần với `y_true` nhất: Mô hình đoán rất đúng. Chúng ta muốn tối ưu hoá `macro avg` F1-Score của **`valid_dataset, test_dataset`** ở bảng sau:"
      ],
      "metadata": {
        "id": "rVgdAS67yN7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_true = [1,1,0,2,3,0,1,3,6]\n",
        "y_pred = [1,1,2,2,2,1,1,4,8]\n",
        "\n",
        "report = classification_report(y_true, y_pred)\n",
        "\n",
        "# Cột đầu tiên là nhãn, các cột sau lần lượt là precision, recall, f1-score cho từng nhãn\n",
        "# Cột support là số nhãn theo từng loại trong y_true\n",
        "# Hàng thứ 3 từ dưới lên là accuracy (độ chính xác)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ge96Z8w7-8YC",
        "outputId": "d64fb724-0cb6-4508-897a-de34c2aec2c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.75      1.00      0.86         3\n",
            "           2       0.33      1.00      0.50         1\n",
            "           3       0.00      0.00      0.00         2\n",
            "           4       0.00      0.00      0.00         0\n",
            "           6       0.00      0.00      0.00         1\n",
            "           8       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.44         9\n",
            "   macro avg       0.15      0.29      0.19         9\n",
            "weighted avg       0.29      0.44      0.34         9\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[ENGLISH BELOW]**\n",
        "\n",
        "**SECTION 2 (100 điểm): [TODO 4]**\n",
        "\n",
        "**TODO 4 : (40 điểm) Xây dựng giao diện (web UI) để tương tác với sản phẩm**\n",
        "\n",
        "- Bạn có thể xây dựng một giao diện phù hợp để tương tác:\n",
        "  - Ví dụ: 1 giao diện cho người dùng upload data và nhận lại file nhãn dán dự báo (predicted labels)\n",
        "\n",
        "------------\n",
        "**[VIETNAMESE ABOVE]**\n",
        "\n",
        "**SECTION 2 (100 points): [TODO 4]**\n",
        "\n",
        "**TODO 4: (40 points) Build interface (web UI) to interact with the product**\n",
        "\n",
        "- You can build an interface suitable for interaction:\n",
        "  - For example: an interface for users to upload data and receive back a predicted labels file.\n"
      ],
      "metadata": {
        "id": "fqdVDXDNAfkU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Chúc các bạn làm bài tập thật tốt 🥰*"
      ],
      "metadata": {
        "id": "sW5vWik7BPK0"
      }
    }
  ]
}