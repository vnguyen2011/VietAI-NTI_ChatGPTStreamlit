{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vnguyen2011/VietAI-NTI_ChatGPTStreamlit/blob/main/ChatPDF_function.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 1 - CHAT PDF\n",
        "Bài tập này tổng bao gồm 100 điểm, với 2 sections:\n",
        "- Section 1 bao gồm TODO 1: 20 điểm tổng\n",
        "- Section 2 bao gồm TODO 2, 3, 4 & 5: 80 điểm tổng\n",
        "\n",
        "This exercise has 100 points total, consists of two sections:\n",
        "- Section 1 includes TODO 1: Total of 20 points.\n",
        "- Section 2 encompasses TODO 2, 3, 4, and 5: Total of 80 points."
      ],
      "metadata": {
        "id": "_I_6Ay1dvABc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Cài đặt và import các thư viện cần thiết"
      ],
      "metadata": {
        "id": "AxKXP6OD4dWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv PyPDF2 streamlit langchain openai faiss-cpu"
      ],
      "metadata": {
        "id": "ivwBLHIruFMw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9a0f27e-d26d-40b7-8503-fc13f2e9f3c9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting streamlit\n",
            "  Downloading streamlit-1.27.2-py2.py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain\n",
            "  Downloading langchain-0.0.322-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata<7,>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.8.0)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.23.5)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (23.2)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.5.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=6.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.6.0)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.5.0)\n",
            "Requirement already satisfied: tzlocal<6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.1)\n",
            "Collecting validators<1,>=0.2 (from streamlit)\n",
            "  Downloading validators-0.22.0-py3-none-any.whl (26 kB)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.2)\n",
            "Collecting watchdog>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-3.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.22)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.6)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.1-py3-none-any.whl (27 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.43 (from langchain)\n",
            "  Downloading langsmith-0.0.51-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.1)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.1.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7,>=1.4->streamlit) (3.17.0)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2023.7.22)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.10.6)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: faiss-cpu, watchdog, validators, smmap, python-dotenv, PyPDF2, mypy-extensions, marshmallow, jsonpointer, typing-inspect, pydeck, langsmith, jsonpatch, gitdb, openai, gitpython, dataclasses-json, langchain, streamlit\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyPDF2-3.0.1 dataclasses-json-0.6.1 faiss-cpu-1.7.4 gitdb-4.0.11 gitpython-3.1.40 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.322 langsmith-0.0.51 marshmallow-3.20.1 mypy-extensions-1.0.0 openai-0.28.1 pydeck-0.8.1b0 python-dotenv-1.0.0 smmap-5.0.1 streamlit-1.27.2 typing-inspect-0.9.0 validators-0.22.0 watchdog-3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "from PyPDF2 import PdfReader\n",
        "import streamlit as st\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain import FAISS\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "7ZqNR-A-9nFm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Cấu hình OpenAI API Key\n",
        "Sau khi đăng ký API key, các bạn chép key giống định dạng sau `sk-L7qQ...DN98XT` vào các chuỗi đang để trống bên dưới."
      ],
      "metadata": {
        "id": "-gl91KJavHoU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "openai.api_key = \"\" ## To configure OpenAI API\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\" ## To configure langchain connections with OpenAI"
      ],
      "metadata": {
        "id": "xmqE4WcgBBbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Chat với đoạn văn ngắn (Section 1)\n",
        "Tiếp theo, chúng ta sẽ thử nghiệm việc chat với đoạn văn ngắn được lấy từ 1 trang PDF (short text/1 page) và hỏi bất cứ thứ gì về nội dung của đoạn văn này."
      ],
      "metadata": {
        "id": "vOSkX-trG3rw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the PDF file to be processed\n",
        "pdf = \"Deep Learning.pdf\"\n",
        "\n",
        "# Initialize an empty list to store chat history\n",
        "chat_history = []\n",
        "\n",
        "# Initialize a PdfReader object to read the PDF file\n",
        "pdf_reader = PdfReader(pdf)\n",
        "\n",
        "# Initialize an empty string to store the extracted text from the PDF\n",
        "text = \"\"\n",
        "\n",
        "# Iterate through the pages of the PDF and extract text from the first page only\n",
        "for i, page in enumerate(pdf_reader.pages):\n",
        "    text += f\"### Page {i}:\\n\\n\" + page.extract_text()\n",
        "    break  # For a single page, we only take the first page\n",
        "\n",
        "# Append a system message to the chat history to set the context\n",
        "chat_history.append({\"role\": \"system\", \"content\": f\"\"\"You are an information retrieval assistant.\n",
        "Text information: {text}\n",
        "\n",
        "### Task: Answer questions using solely the information from the above text\"\"\"})"
      ],
      "metadata": {
        "id": "Sr5LW_DzCsif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tiếp theo, chúng ta sẽ định nghĩa hàm `ask_question` với đầu vào là câu hỏi `question`. Ngoài ra, hàm này còn khai thác lịch sử trò chuyện qua biến toàn cục `chat_history`."
      ],
      "metadata": {
        "id": "eF0KSeYVvMv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to ask questions and interact with the AI model\n",
        "def ask_question(question):\n",
        "    global chat_history\n",
        "    chat_history.append({\"role\": \"user\", \"content\": question})\n",
        "\n",
        "    # Define parameters for the OpenAI ChatCompletion API\n",
        "    params = dict(model=\"gpt-3.5-turbo\", messages=chat_history)\n",
        "\n",
        "    # Generate a response from the AI model\n",
        "    response = openai.ChatCompletion.create(**params)\n",
        "    content = response.choices[0].message.content\n",
        "    chat_history.append({\"role\": \"assistant\", \"content\": content})\n",
        "\n",
        "    # Print and return the assistant's response\n",
        "    print(content)"
      ],
      "metadata": {
        "id": "k0ogW1AgCsll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bắt đầu thử nghiệm thôi!"
      ],
      "metadata": {
        "id": "3kDuUdU0vSSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ask_question(\"What's NN? Answer in less than 30 words\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXWBlAAjI77S",
        "outputId": "dcb6603d-b72d-414d-d7db-2b6dce9af9aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NN stands for Neural Network, which is a computational model inspired by the structure and function of the human brain, used in deep learning for various applications.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ask_question(\"Translate the above to Vietnamese\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_RzfEpWKWrE",
        "outputId": "eaeaa2c5-1300-4462-b525-d8bf4dc2fc0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NN viết tắt của Neural Network, đây là một mô hình tính toán được lấy cảm hứng từ cấu trúc và chức năng của não người, được sử dụng trong deep learning cho các ứng dụng khác nhau.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "owqn9TK5egXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[ENGLISH BELOW]**\n",
        "\n",
        "**SECTION 1 (20 points): [TODO 1]**\n",
        "\n",
        "**TODO 1: (20 points)**\n",
        "\n",
        "- Hiện tại, hàm `ask_question` nối tiếp câu hỏi `question` và nội dung trả lời `content` vào biến toàn cục `chat_history`. Điều này sẽ giúp cho đoạn hội thoại có tính liên tục. Như ví dụ dịch nội dung trên, OpenAI chỉ dịch câu trả lời trước đó (về mạng NN) chứ không phải dịch tài liệu gốc. Tuy nhiên, hiện tại nó thiếu khả năng chỉnh sửa các cuộc trò chuyện trong quá khứ hoặc đặt lại cuộc trò chuyện. Cần phát triển tiếp các chức năng reset cuộc trò chuyện, delete hoặc edit các câu hỏi trước đó, tương tự như giao diện ChatGPT.\n",
        " - `ask_question(\"Translate the above to Vietnamese\", reset_chat=True)` sẽ reset lịch sử chat\n",
        " - `ask_question(\"Translate the above to German\", edit_last_question=True)` sẽ chỉnh sửa tại chỗ câu hỏi cuối cùng trong `chat_history` và lấy câu trả lời mới\n",
        "\n",
        "------------\n",
        "**[VIETNAMESE ABOVE]**\n",
        "\n",
        "**SECTION 1 (20 points): [TODO 1]**\n",
        "\n",
        "**TODO 1: (20 points)**\n",
        "\n",
        "- Currently, the `ask_question` function appends the question `question` and the corresponding answer content `content` to the global variable `chat_history`. This ensures a continuous conversation flow, as demonstrated in the previous content translation example. OpenAI translates only the preceding answer (related to neural networks) rather than translating the original document. However, it currently lacks the capability to edit past conversations or reset the conversation. Further development is needed to introduce functions to reset the conversation, delete, or edit previous questions, similar to the ChatGPT interface.\n",
        "   - `ask_question(\"Translate the above to Vietnamese\", reset_chat=True)` will reset the chat history.\n",
        "   - `ask_question(\"Translate the above to German\", edit_last_question=True)` will allow editing of the last question in the `chat_history` and retrieving a new response.\n"
      ],
      "metadata": {
        "id": "_47uTMhDNDVe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Chat với đoạn văn dài (Section 2)\n",
        "Do độ dài ngữ cảnh hạn chế, ta không thể đưa toàn bộ 100 trang vào các tương tác OpenAI của mình, cả về tính thực tế lẫn chi phí. Do đó, ta phải chia nhỏ các tài liệu dựa trên các yếu tố như kích thước văn bản hoặc các tiêu chí liên quan khác.\n",
        "\n",
        "Trong trường hợp này, ta chia theo trang, mặc dù một số trang có số lượng token vượt quá giới hạn ký tự tiêu chuẩn là 4K token. Lựa chọn này cho phép ta tham chiếu chính xác trang nào đang được tương tác và thảo luận."
      ],
      "metadata": {
        "id": "higHdOV7K6VK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the PDF file to be processed\n",
        "pdf = \"Deep Learning.pdf\"\n",
        "\n",
        "# Initialize a PdfReader object to read the PDF file\n",
        "pdf_reader = PdfReader(pdf)\n",
        "\n",
        "# Initialize an empty string to store the extracted text from the PDF\n",
        "chunks = []\n",
        "\n",
        "# Iterate through the pages of the PDF and extract text from each page\n",
        "for i, page in enumerate(pdf_reader.pages):\n",
        "    chunks.append(f\"### Page {i}:\\n\\n\" + page.extract_text())\n",
        "\n",
        "# Print the number of pages in the PDF\n",
        "print(\"Number of pages:\", len(pdf_reader.pages))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHJ8UznhLzaM",
        "outputId": "901190d6-ef72-40fd-9040-e58a0ead27f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of pages: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tiếp theo, ta sẽ viết hàm `process_text` để xử lý toàn bộ nội dung các trang trong file PDF.\n",
        "\n",
        "Chúng ta sẽ biểu diễn các trang sách bằng các vector ngôn ngữ (`embeddings = OpenAIEmbeddings()`). Khi trả lời câu hỏi, chúng ta đầu tiên sẽ chọn ra trang có embeddings gần nhất với câu hỏi `knowledgeBase.similarity_search`, và sẽ sử dụng thông tin trong trang tìm được để trả lời."
      ],
      "metadata": {
        "id": "g9zjIDOOwlge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpQc2NIhanIF",
        "outputId": "288f9ebb-fedf-4de7-d8cc-0b0cebb0196d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to process the extracted text\n",
        "def process_text(chunks):\n",
        "    # Convert the chunks of text into embeddings to form a knowledge base\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "    knowledgeBase = FAISS.from_texts(chunks, embeddings)\n",
        "\n",
        "    return knowledgeBase\n",
        "\n",
        "# Process the extracted text to create a knowledge base\n",
        "knowledgeBase = process_text(chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5NJw_QtAj22",
        "outputId": "ac45c9d4-3a5d-4643-b6fa-af7c016ee7f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.text_splitter:Created a chunk of size 5432, which is longer than the specified 4000\n",
            "WARNING:langchain.text_splitter:Created a chunk of size 7851, which is longer than the specified 4000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "knowledgeBase"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COZoSG8OassN",
        "outputId": "a7c90f0a-d294-453c-9b63-405c8cf34b6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain.vectorstores.faiss.FAISS at 0x7b75116fe860>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a question for which you want to find an answer\n",
        "question = \"What is Logistic regression cost function?\"\n",
        "\n",
        "# Use embeddings similarity search to search for the closest document (RAG)\n",
        "docs = knowledgeBase.similarity_search(question)\n",
        "llm = OpenAI()\n",
        "chain = load_qa_chain(llm, chain_type='stuff')\n",
        "\n",
        "# Run the question-answering chain to find the answer to the question\n",
        "response = chain.run(input_documents=docs, question=question)\n",
        "\n",
        "# Print the response\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fANfy1dy98d4",
        "outputId": "a9ed5b2a-88d6-4277-e368-8ffc455824b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The Logistic regression cost function is J(w,b) = (1/m) * Sum(L(y'[i],y[i])) where L(y',y) = - (y*log(y') + (1-y)*log(1-y')).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "id": "T8TqWTUCCFue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b885606-9160-4b26-f463-391b037a4c01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content=\"Page 2:\\n\\nNeural Netw orks Basics\\nLearn to set up a machine learning problem with a neural network mindset. Learn to use vectorization to speed up your\\nmodels.\\nBinar y classification\\nMainly he is talking about how to do a logistic regression to make a binary classifier.\\nImage taken from 3.bp.blogspot.com\\nHe talked about an example of knowing if the current image contains a cat or not.\\nHere are some notations:\\nM is the number of training vectors\\nNx is the size of the input vector\\nNy is the size of the output vector\\nX(1) is the first input vector\\nY(1) is the first output vector\\nX = [x(1) x(2).. x(M)]\\nY = (y(1) y(2).. y(M))\\nWe will use python in this course.\\nIn NumPy we can make matrices and make operations on them in a fast and reliable time.\\nLogistic r egression\\nAlgorithm is used for classification algorithm of 2 classes.\\nEquations:\\nSimple equation: y = wx + b\\nIf x is a vector: y = w(transpose)x + b\\nIf we need y to be in between 0 and 1 (probability): y = sigmoid(w(transpose)x + b)\\nIn some notations this might be used: y = sigmoid(w(transpose)x)\\nWhile b is w0 of w and we add x0 = 1. but we won't use this notation in the course (Andrew said that the\\nfirst notation is better).\\nIn binary classification Y has to be between 0 and 1.\\nIn the last equation w is a vector of Nx and b is a real number\\nLogistic r egression cost function\\nFirst loss function would be the square root error: L(y',y) = 1/2 (y' - y)^2\\nBut we won't use this notation because it leads us to optimization problem which is non convex, means it contains\\nlocal optimum points.\\nThis is the function that we will use: L(y',y) = - (y*log(y') + (1-y)*log(1-y'))\\nTo explain the last function lets see:\\nif y = 1 ==> L(y',1) = -log(y') ==> we want y' to be the largest ==> y' biggest value is 1\\nif y = 0 ==> L(y',0) = -log(1-y') ==> we want 1-y' to be the largest ==> y' to be smaller as possible\\nbecause it can only has 1 value.\\nThen the Cost function will be: J(w,b) = (1/m) * Sum(L(y'[i],y[i]))\\nThe loss function computes the error for a single training example; the cost function is the average of the loss functions\\nof the entire training set.\\nGradient Descent\\nWe want to predict w and b that minimize the cost function.\\nOur cost function is convex.\\nFirst we initialize w and b to 0,0 or initialize them to a random value in the convex function and then try to improve\\nthe values the reach minimum value.\\nIn Logistic regression people always use 0,0 instead of random.\\nThe gradient decent algorithm repeats: w = w - alpha * dw where alpha is the learning rate and dw is the derivative of\\nw (Change to w) The derivative is also the slope of w\\nLooks like greedy algorithms. the derivative give us the direction to improve our parameters.\"),\n",
              " Document(page_content='Page 14:\\n\\nThe normal cost function that we want to minimize is:\\nJ(W1,b1...,WL,bL) = (1/m) * Sum(L(y(i),y\\'(i)))\\nThe L2 regularization version:\\nJ(w,b) = (1/m) * Sum(L(y(i),y\\'(i))) + (lambda/2m) * Sum((||W[l]||^2)\\nWe stack the matrix as one vector (mn,1) and then we apply sqrt(w1^2 + w2^2.....)\\nTo do back propagation (old way):\\ndw[l] = (from back propagation)\\nThe new way:\\ndw[l] = (from back propagation) + lambda/m * w[l]\\nSo plugging it in weight update step:\\nw[l] = w[l] - learning_rate * dw[l] \\n     = w[l] - learning_rate * ((from back propagation) + lambda/m * w[l]) \\n     = w[l] - (learning_rate*lambda/m) * w[l] - learning_rate * (from back propagation)  \\n     = (1 - (learning_rate*lambda)/m) * w[l] - learning_rate * (from back propagation) \\nIn practice this penalizes large weights and effectively limits the freedom in your model.\\nThe new term (1 - (learning_rate*lambda)/m) * w[l] causes the weight t o decay  in proportion to its size.\\nWhy r egularization r educes ov erfitting?\\nHere are some intuitions:\\nIntuition 1:\\nIf lambda is too large - a lot of w\\'s will be close to zeros which will make the NN simpler (you can think of it as it\\nwould behave closer to logistic regression).\\nIf lambda is good enough it will just reduce some weights that makes the neural network overfit.\\nIntuition 2 (with tanh activation function):\\nIf lambda is too large, w\\'s will be small (close to zero) - will use the linear part of the tanh activation function, so we\\nwill go from non linear activation to roughly  linear which would make the NN a roughly  linear classifier.\\nIf lambda good enough it will just make some of tanh activations roughly  linear which will prevent overfitting.\\nImplementation tip : if you implement gradient descent, one of the steps to debug gradient descent is to plot the cost\\nfunction J as a function of the number of iterations of gradient descent and you want to see that the cost function J\\ndecreases monot onically  after every elevation of gradient descent with regularization. If you plot the old definition of J (no\\nregularization) then you might not see it decrease monotonically.\\nDropout R egularization\\nIn most cases Andrew Ng tells that he uses the L2 regularization.\\nThe dropout regularization eliminates some neurons/weights on each iteration based on a probability.\\nA most common technique to implement dropout is called \"Inverted dropout\".\\nCode for Inverted dropout:\\nkeep_prob = 0.8   # 0 <= keep_prob <= 1 \\nl = 3  # this code is only for layer 3\\n# the generated number that are less than 0.8 will be dropped. 80% stay, 20% dropped \\nd3 = np.random.rand(a[l].shape[0], a[l].shape[1]) < keep_prob \\n \\na3 = np.multiply(a3,d3)   # keep only the values in d3 \\n \\n# increase a3 to not reduce the expected value of output\\n# (ensures that the expected value of a3 remains the same) - to solve the scaling problem \\na3 = a3 / keep_prob       \\nVector d[l] is used for forward and back propagation and is the same for them, but it is different for each iteration (pass)\\nor training example.\\nAt test time we don\\'t use dropout. If you implement dropout at test time - it would add noise to predictions.\\nUnder standing Dr opout\\nIn the previous video, the intuition was that dropout randomly knocks out units in your network. So it\\'s as if on every\\niteration you\\'re working with a smaller NN, and so using a smaller NN seems like it should have a regularizing effect.\\nAnother intuition: can\\'t rely on any one feature, so have to spread out weights.\\nIt\\'s possible to show that dropout has a similar effect to L2 regularization.'),\n",
              " Document(page_content=\"Page 25:\\n\\nTraining a So ftmax classifier\\nThere's an activation which is called hard max, which gets 1 for the maximum value and zeros for the others.\\nIf you are using NumPy, its np.max over the vertical axis.\\nThe Softmax name came from softening the values and not harding them like hard max.\\nSoftmax is a generalization of logistic activation function to C classes. If C = 2 softmax reduces to logistic regression.\\nThe loss function used with softmax:\\nL(y, y_hat) = - sum(y[j] * log(y_hat[j])) # j = 0 to C-1 \\nThe cost function used with softmax:\\nJ(w[1], b[1], ...) = - 1 / m * (sum(L(y[i], y_hat[i]))) # i = 0 to m \\nBack propagation with softmax:\\ndZ[L] = Y_hat - Y \\nThe derivative of softmax is:\\nY_hat * (1 - Y_hat) \\nExample: \\nDeep learning framew orks\\nIt's not practical to implement everything from scratch. Our numpy implementations were to know how NN works.\\nThere are many good deep learning frameworks.\\nDeep learning is now in the phase of doing something with the frameworks and not from scratch to keep on going.\\nHere are some of the leading deep learning frameworks:\\nCaffe/ Caffe2\\nCNTK\\nDL4j\\nKeras\\nLasagne\\nmxnet\\nPaddleP addle\\nTensorFlow\\nTheano\\nTorch/Pytorch\\nThese frameworks are getting better month by month. Comparison between them can be found here.\\nHow to choose deep learning framework:\\nEase of programming (development and deployment)\\nRunning speed\\nTruly open (open source with good governance)\\nProgramming frameworks can not only shorten your coding time but sometimes also perform optimizations that speed\\nup your code.\\nTensorFlow\"),\n",
              " Document(page_content='Page 18:\\n\\nObser vations :\\nThe value of λ is a hyperparameter that you can tune using a dev set.\\nL2 regularization makes your decision boundary smoother. If λ is too large, it is also possible to \"oversmooth\", resulting\\nin a model with high bias.\\nWhat is L2-r egularization actually doing? :\\nL2-regularization relies on the assumption that a model with small weights is simpler than a model with large weights.\\nThus, by penalizing the square values of the weights in the cost function you drive all the weights to smaller values. It\\nbecomes too costly for the cost to have large weights! This leads to a smoother model in which the output changes\\nmore slowly as the input changes.\\nWhat y ou should r emember :\\nImplications of L2-regularization on:\\ncost computation:\\nA regularization term is added to the cost\\nbackpropagation function:\\nThere are extra terms in the gradients with respect to weight matrices\\nweights:\\nweights end up smaller (\"weight decay\") - are pushed to smaller values.\\n2. Dr opout\\nWhat y ou should r emember about dr opout:\\nDropout is a regularization technique.\\nYou only use dropout during training. Don\\'t use dropout (randomly eliminate nodes) during test time.\\nApply dropout both during forward and backward propagation.\\nDuring training time, divide each dropout layer by keep_prob to keep the same expected value for the activations. For\\nexample, if keep_prob is 0.5, then we will on average shut down half the nodes, so the output will be scaled by 0.5 since\\nonly the remaining half are contributing to the solution. Dividing by 0.5 is equivalent to multiplying by 2. Hence, the\\noutput now has the same expected value. Y ou can check that this works even when keep_prob is other values than 0.5.\\nOptimization algorithms\\nMini-b atch gradient descent\\nTraining NN with a large data is slow. So to find an optimization algorithm that runs faster is a good idea.\\nSuppose we have m = 50 million. To train this data it will take a huge processing time for one step.\\nbecause 50 million won\\'t fit in the memory at once we need other processing to make such a thing.\\nIt turns out you can make a faster algorithm to make gradient descent process some of your items even before you\\nfinish the 50 million items.\\nSuppose we have split m to mini b atches of size 1000.\\nX{1} = 0 ... 1000\\nX{2} = 1001 ... 2000\\n...\\nX{bs} = ...\\nWe similarly split X & Y.\\nSo the definition of mini batches ==> t: X{t}, Y{t}\\nIn Batch gradient descent  we run the gradient descent on the whole dataset.\\nWhile in Mini-Bat ch gradient descent  we run the gradient descent on the mini datasets.\\nMini-Batch algorithm pseudo code:\\nfor t = 1:No_of_batches                         # this is called an epoch \\n AL, caches = forward_prop(X{t}, Y{t}) \\n cost = compute_cost(AL, Y{t}) \\n grads = backward_prop(AL, caches) \\n update_parameters(grads) \\nThe code inside an epoch should be vectorized.\\nMini-batch gradient descent works much faster in the large datasets.\\nUnder standing mini-b atch gradient descent\\nIn mini-batch algorithm, the cost won\\'t go down with each step as it does in batch algorithm. It could contain some ups\\nand downs but generally it has to go down (unlike the batch gradient descent where cost function descreases on each')]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**[ENGLISH BELOW]**\n",
        "\n",
        "**SECTION 2 (80 points tổng): [TODO 2, 3, 4, & 5]**\n",
        "\n",
        "Để phát triển các tính năng trong tương lai, ta đã vạch ra một số nhiệm vụ chính dự định thực hiện:\n",
        "\n",
        "**TODO 2: (20 points)**\n",
        "Hiện tại, mỗi khi người dùng đặt câu hỏi, ta sẽ thực hiện quy trình\n",
        "`knowBase.similarity_search` để xác định trang có liên quan chặt chẽ nhất với câu hỏi xét về mức độ tương đồng nội dung. Điều này là cần thiết vì ta không thể chứa tất cả 100 trang trong giới hạn của OpenAI. Để nâng cao trải nghiệm người dùng, ứng dụng cho phép người dùng xác thực và tiếp tục cuộc trò chuyện của họ trong bối cảnh của cùng một trang, loại bỏ nhu cầu truy xuất tài liệu mới.\n",
        "\n",
        "   - Input: `question`\n",
        "   - Output: `def answer(question, retrieve_new_page=False)` - Cho phép người dùng tìm hiểu về trang hiện tại mà không cần chuyển đổi.\n",
        "\n",
        "**TODO 3 (20 points): Chỉ chọn MỘT trong các ý 3.1 & 3.2**\n",
        "\n",
        "**TODO 3.1:**\n",
        "Hãy tưởng tượng một tình huống trong đó trang chính xác được truy xuất nhưng thông tin cần thiết cũng có thể được tìm thấy trên các trang tiếp theo. Để tạo điều kiện thuận lợi cho việc trả lời câu hỏi, ta sẽ triển khai một chức năng cho phép người dùng truy cập các trang tiếp theo để có thêm thông tin.\n",
        "\n",
        "   - Input: `question`\n",
        "   - Output: `def answer(question, retrieve_next_page=True)` - Cho phép người dùng đặt câu hỏi liên quan đến trang tiếp theo.\n",
        "\n",
        "**TODO 3.2:**\n",
        "Ta sẽ cung cấp cho người dùng khả năng linh hoạt để mở rộng các trang tài liệu khác nếu họ cho rằng câu trả lời hiện tại không chính xác hoặc nếu họ muốn tìm kiếm trong một trang cụ thể mà họ cho rằng có chứa thông tin liên quan.\n",
        "\n",
        "   - Input: `question`\n",
        "   - Output: `def answer(question, retrieve_page_id=[10, 11])` - Cho phép người dùng chọn lựa đến các trang cụ thể (vd., trang 10 hoặc 11) HOẶC `def answer(question, retrieve_diff_page=True)` để khám phá các trang khác nhau.\n",
        "\n",
        "**TODO 4 (10 points):**\n",
        "\n",
        "Ta lường trước đến việc cung cấp cho người dùng khả năng yêu cầu thông tin từ các nguồn bên ngoài, vượt ra ngoài giới hạn của các tệp PDF hiện tại.\n",
        "\n",
        "   - Input: `question`\n",
        "   - Output: `def answer(question, retrieve_external_knowledge=True)` - Cho phép người dùng tìm kiếm thông tin ngoài phạm vi của các file PDF hiện tại.\n",
        "\n",
        "**TODO 5: (30 points)**\n",
        "\n",
        "Để đảm bảo tính thân thiện với người dùng, chúng ta sẽ tạo ra một giao diện trực quan và tương tác cho ứng dụng này. Ta có thể tận dụng các công cụ như Streamlit hoặc Gradio để tạo ra ứng dụng tương tác hấp dẫn với người dùng.\n",
        "\n",
        "   - Input: PDFs\n",
        "   - Output: Giao diện người dùng cho phép người dùng tải lên các file PDF, xem nội dung và đặt câu hỏi một cách tương tác. Ta sẽ quay video giới thiệu ứng dụng. Đánh giá sẽ dựa trên tính thân thiện với người dùng, khả năng trình diễn và tính tương tác. Những bài nộp đặc biệt có thể được trình bày trong ngày giới thiệu lớp học của mình và được giới thiệu trên trang Facebook VietAI.\n",
        "\n",
        "Những sáng kiến phát triển này nhằm mục đích nâng cao chức năng, tính linh hoạt và trải nghiệm người dùng.\n",
        "\n",
        "----------------------------------\n",
        "**[VIETNAMESE ABOVE]**\n",
        "\n",
        "**SECTION 2 (80 points total): [TODO 2, 3, 4, & 5]**\n",
        "\n",
        "In terms of our future development goals, we have outlined several key tasks that we plan to undertake:\n",
        "\n",
        "**TODO 2: (20 points)**\n",
        "\n",
        "Currently, each time a user poses a question, we execute the `knowledgeBase.similarity_search` process to identify the page most closely related to the question in terms of embeddings similarity. This is necessary because we cannot accommodate all 100 pages within OpenAI's constraints. To enhance the user experience, we aim to introduce functionality that allows users to validate and continue their chat within the context of the same page, eliminating the need to retrieve a new document.\n",
        "\n",
        "\n",
        "**TODO 3 (20 points): Choose ONLY 1 option between 3.1 & 3.2**\n",
        "\n",
        "**TODO 3.1:**\n",
        "\n",
        "Imagine a scenario where the correct page has already been retrieved, but the required information might also be found on subsequent pages. To facilitate this exploration, we plan to implement a function that permits users to access the next pages for additional information.\n",
        "\n",
        "   - Input: `question`\n",
        "   - Output: `def answer(question, retrieve_next_page=True)` - Allows users to ask questions related to the next pages.\n",
        "\n",
        "**TODO 3.2:**\n",
        "\n",
        "We will provide users with the flexibility to explore entirely new pages if they believe the current answer is incorrect or if they wish to search in a specific page they believe contains relevant information.\n",
        "\n",
        "   - Input: `question`\n",
        "   - Output: `def answer(question, retrieve_page_id=[10, 11])` - Allows users to select specific pages (e.g., page 10 or 11) OR `def answer(question, retrieve_diff_page=True)` to explore different pages.\n",
        "\n",
        "**TODO 4 (10 points):**\n",
        "\n",
        "Our vision includes offering users the ability to request information from external sources, extending beyond the confines of the current PDFs.\n",
        "\n",
        "   - Input: `question`\n",
        "   - Output: `def answer(question, retrieve_external_knowledge=True)` - Allow users to search for information beyond the scope of the current PDF files.\n",
        "\n",
        "**TODO 5: (30 points)**\n",
        "\n",
        "As a demonstration of our commitment to user-friendliness, we aspire to create an intuitive and interactive interface for this application. We are considering leveraging tools like Streamlit or Gradio to achieve a seamless and engaging user interaction.\n",
        "\n",
        "   - Input: PDFs\n",
        "   - Output: A user interface enabling users to upload PDF files, view the content, and interactively ask questions. We will record a video showcasing the application. Evaluation will be based on user-friendliness, demonstrability, and interactivity. Exceptional submissions may be presented on our class demo day and featured on the VietAI Facebook page.\n",
        "\n",
        "These development initiatives are aimed at enhancing the functionality, versatility, and user experience of our application. We are committed to continually improving the system to meet the evolving needs of our users."
      ],
      "metadata": {
        "id": "ASzHCRKkOofR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IGrQD9VDVFa0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}